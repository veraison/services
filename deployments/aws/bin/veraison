#!/usr/bin/env python
# pyright: reportOptionalMemberAccess=false
# pyright: reportOptionalSubscript=false
# pyright: reportOperatorIssue=false
import argparse
import asyncio
import getpass
import inspect
import logging
import os
import pprint
import random
import re
import shutil
import socket
import stat
import string
import sys
import time
from asyncio.subprocess import Process, PIPE
from collections import defaultdict
from copy import copy
from urllib.parse import urlparse

import boto3
import fabric
import requests
import xdg.BaseDirectory
import yaml
from botocore.exceptions import ClientError
from envsubst import envsubst
from sqlitedict import SqliteDict


COLOR_DARK_GREY = '\x1b[38;5;245m'
COLOR_MEDIUM_GREY = '\x1b[38;5;250m'
COLOR_GREY = '\x1b[38;20m'
COLOR_GREEN = '\x1b[38;5;2m'
COLOR_YELLOW = '\x1b[33;20m'
COLOR_RED = '\x1b[31;20m'
COLOR_BOLD_RED = '\x1b[31;1m'
COLOR_RESET = '\x1b[0m'
']]]]]]]]'  # "close" the brackets above to fix nvim's auto-indent


class Aws:

    client_name_map = {
        'cf': 'cloudformation',
    }

    def __init__(self, **kwargs):
        self.session = boto3.Session(**kwargs)
        self.clients = {}

    def close(self):
        for client in self.clients.values():
            client.close()
        self.clients = {}

    def __getattr__(self, name):
        client_name = self.client_name_map.get(name, name)
        if client_name not in self.clients:
            self.clients[client_name] = self.session.client(client_name)
        return self.clients[client_name]

    def __del__(self):
        self.close()


def randomword(n=32, use_punctuation=False):
    alphabet = string.ascii_letters + string.digits
    if use_punctuation:
        alphabet += string.punctuation
    return ''.join(random.choice(alphabet) for _ in range(n))


def camel_to_kebab(name: str):
    words = []
    current = ''
    for char in name:
        if char.isupper():
            if current:
                words.append(current)
            current = char.lower()
        else:
            current += char

    if current:
        words.append(current)

    return '-'.join(words)


def get_public_ip_address():
    resp = requests.get('http://ifconfig.me')
    if resp.status_code != 200:
        raise RuntimeError(
                f'could not access http://ifconfig.me: {resp.reason} ({resp.status_code})')
    return resp.text


def authorize_ports_for_address(aws, group_id, addr, ports, tag, deployment_tags):
    permissions = []
    for port in ports:
        permissions.append({
            'FromPort': port,
            'ToPort': port,
            'IpProtocol': 'tcp',
            'IpRanges': [{'CidrIp': f'{addr}/32'}],
        })

    tags = copy(deployment_tags)
    tags.append({'Key': 'dynamic-address', 'Value': tag})

    aws.ec2.authorize_security_group_ingress(
        GroupId=group_id,
        IpPermissions=permissions,
        TagSpecifications=[
            {
                'ResourceType': 'security-group-rule',
                'Tags': tags,
            }
        ],
    )


def revoke_security_group_rules_by_tag(aws, group_id, tag):
    resp = aws.ec2.describe_security_group_rules(
        Filters=[
            {
                'Name': 'group-id',
                'Values': [group_id],
            },
            {
                'Name': 'tag:dynamic-address',
                'Values': [tag],
            }
        ],
    )

    rule_ids = [sgr['SecurityGroupRuleId'] for sgr in resp['SecurityGroupRules']]
    if not rule_ids:
        return

    aws.ec2.revoke_security_group_ingress(
        GroupId=group_id,
        SecurityGroupRuleIds=rule_ids,
    )


def command_create_packer_security_group(cmd, deployment_name):
    vpc_id = command_get(cmd, 'vpc.vpc-id', 'VPC stack been created')

    cmd.logger.debug('creating Packer security group...')
    resp = cmd.aws.ec2.create_security_group(
        GroupName='veraison-packer',
        Description='Temporary security group for creating Veraison packer imeages',
        VpcId=vpc_id,
        TagSpecifications=[
            {
                'ResourceType': 'security-group',
                'Tags': [
                    {'Key': 'veraison-deployment', 'Value': deployment_name},
                    {'Key': 'Class', 'Value': 'packer'},
                ],
            }
        ],
    )

    cmd.logger.debug('obtaining public IP address for localhost...')
    my_addr = get_public_ip_address()

    cmd.logger.debug('Adding access rule for SSH from localhost...')
    authorize_ports_for_address(
        cmd.aws, resp['GroupId'], my_addr, [22], cmd.cache.user_tag,
        deployment_tags=[
            {'Key': 'veraison-deployment', 'Value': deployment_name},
            {'Key': 'Class', 'Value': 'packer'},
        ],
    )


def command_delete_packer_security_group(cmd, deployment_name):
    cmd.logger.debug(f'looking for packer group(s) for deployment {deployment_name}...')
    resp = cmd.aws.ec2.describe_security_groups(
        Filters=[
            {'Name': 'tag:veraison-deployment', 'Values': [deployment_name]},
            {'Name': 'tag:Class', 'Values': ['packer']},
        ]
    )

    group_ids = [sgr['GroupId'] for sgr in resp['SecurityGroups']]
    if not group_ids:
        cmd.logger.debug(f'no packer group found for deployment {deployment_name}')
        return

    for group_id in group_ids:
        cmd.logger.debug(f'deleting security group {group_id}...')
        cmd.aws.ec2.delete_security_group(GroupId=group_id)


def command_update_dynamic_address_rules(cmd, deployment_name, group_names, tag, ports):
    resp = aws.ec2.describe_security_groups(
        Filters=[
            {
                'Name': 'tag:veraison-deployment',
                'Values': [deployment_name],
            },
            {
                'Name': 'group-name',
                'Values': group_names,
            },
        ]
    )

    group_ids = [sgr['GroupId'] for sgr in resp['SecurityGroups']]
    if not group_ids:
        cmd.logger.info(f'no groups found for deployment {deployment_name}')
        return

    my_addr = get_public_ip_address()
    for group_id in group_ids:
        revoke_security_group_rules_by_tag(cmd.aws, group_id, tag)
        authorize_ports_for_address(
                cmd.aws, group_id, my_addr, ports, tag,
                deployment_tags=[{'Key': 'veraison-deployment', 'Value': deployment_name}])


def command_get_hosted_zone(cmd, dns_name):
    cmd.logger.debug(f'looking up hosted zone of {dns_name}...')
    resp = cmd.aws.route53.list_hosted_zones()
    for hz in resp['HostedZones']:
        if hz['Name'] == f'{dns_name}.':
            return hz['Id'].strip('/hostedzone/')
    else:
        cmd.fail(f'Could not find hosted zone for {dns_name}')


def get_stack_instances_info(aws, stack_name):
    resp = aws.cf.describe_stack_resources(StackName=stack_name)

    info = {}

    for resource in resp['StackResources']:
        if resource['ResourceType'] == 'AWS::EC2::Instance':
            instance_id = resource['PhysicalResourceId']
            update_info_with_ec2_instance(aws, info, instance_id)
        elif resource['ResourceType'] == 'AWS::RDS::DBInstance':
            instance_id = resource['PhysicalResourceId']
            update_info_with_rds_instance(aws, info, instance_id)

    return info


def update_info_with_rds_instance(aws, info, instance_id):
    resp = aws.rds.describe_db_instances(DBInstanceIdentifier=instance_id)
    instance = resp['DBInstances'][0]

    instance_name = None
    for tag in instance['TagList']:
        if tag['Key'] == 'deployment-instance-name':
            instance_name = tag['Value']
            break

    if not instance_name:
        # if not explicitly named, assume it's the sole RDS instance for the deployment
        instance_name = 'rds'

    info[instance_name] = {
        'id': instance_id,
        'dns_name': instance['Endpoint']['Address'],
        'port': instance['Endpoint']['Port'],
    }


def update_info_with_ec2_instance(aws, info, instance_id):
    resp = aws.ec2.describe_instances(InstanceIds=[instance_id])
    instance = resp['Reservations'][0]['Instances'][0]

    instance_name = None
    fallback_name = instance_id
    for tag in instance['Tags']:
        if tag['Key'] == 'deployment-instance-name':
            instance_name = tag['Value']
            break
        elif tag['Key'] == 'Name':
            fallback_name = tag['Value']

    if not instance_name:
        instance_name = fallback_name

    pub_iface = instance['NetworkInterfaces'][0]['Association']

    info[instance_name] = {
            'id': instance_id,
            'dns_name': pub_iface["PublicDnsName"],
            'ip_address': pub_iface["PublicIp"],
    }


def get_ami_id(aws, name):
    resp = aws.ec2.describe_images(Owners=['self'])
    for image in resp['Images']:
        if image['Name'] == name:
            return image['ImageId']


def run_in_shell(cmd, should_log):
    logger = logging.getLogger('shell')
    if should_log:
        logger.setLevel(logging.DEBUG)

    loop = asyncio.new_event_loop()
    try:
        return loop.run_until_complete(_run_in_shell_teed(cmd, logger))
    finally:
        loop.close()


async def _run_in_shell_teed(cmd, logger):
    process: Process = await asyncio.create_subprocess_shell(
            cmd, stdout=PIPE, stderr=PIPE, cwd=os.getcwd())


    stdout_buf, stderr_buf = [], []
    tasks = {
        asyncio.Task(process.stdout.readline()): (process.stdout, stdout_buf),
        asyncio.Task(process.stderr.readline()): (process.stderr, stderr_buf),
    }

    while tasks:
        done, _ = await asyncio.wait(
                tasks, return_when=asyncio.FIRST_COMPLETED)  # pyright: ignore[reportCallIssue]
        for future in done:
            stream, buf = tasks.pop(future)
            line = future.result()
            if line:
                line = line.decode()
                buf.append(line)
                logger.debug(line.rstrip('\n'))
                tasks[asyncio.Task(stream.readline())] = stream, buf  # pyright: ignore[reportOptionalMemberAccess]

    rc = await process.wait()
    return rc, ''.join(stdout_buf), ''.join(stderr_buf)


def command_get_config(cmd, name):
    try:
        return cmd.cache[name]
    except KeyError:
        cmd.fail(f'could not get {name} from cache; has configure command been run?')


def command_get(cmd, path, precondition=None):
    val = cmd.cache.get(path)
    if val is None:
        if precondition:
            cmd.fail(f'could not get {path} from cache; has {precondition}?')
        else:
            cmd.fail(f'could not get {path} from cache')
    return val


def command_instantiate_template(cmd, deployment_name, src_path, out_dir='/tmp'):
    with open(src_path) as fh:
        instantiated_template_body = envsubst(fh.read())

    basename = os.path.basename(src_path).removesuffix('.template')
    out_path = os.path.join(out_dir, f'{deployment_name}-{basename}')
    cmd.logger.debug(f'writing {out_path}')
    with open(out_path, 'w') as wfh:
        wfh.write(instantiated_template_body)

    return out_path


def command_create_image(cmd, args, name, packer_params=None):
    if not shutil.which('packer'):
        cmd.fail('packer must be installed on the system')

    if not os.path.isfile(args.template):
        cmd.fail(f'template {args.template} does not exist')

    full_name = f'{args.deployment_name}-{name}'
    cmd.logger.info(f'creating image: {full_name}...')

    command_create_packer_security_group(cmd, args.deployment_name)

    try:
        cmd.logger.debug('checking for existing AMI with that name...')
        existing_id = get_ami_id(cmd.aws, full_name)
        if existing_id:
            if not args.force:
                cmd.fail(f'image {full_name} already exits (use -f to overwrite)')
            cmd.logger.info('removing existing image...')
            cmd.aws.ec2.deregister_image(ImageId=existing_id)

        cmd.logger.info('building using packer...')
        region = command_get_config(cmd, 'region')
        vpc_id = command_get(cmd, 'vpc.vpc-id', 'VPC stack been created')
        subnet_id = command_get(cmd, 'vpc.public-subnet-a-id', 'VPC stack been created')

        params_dict = {
            'ami_name': full_name,
            'deployment_name': args.deployment_name,
            'instance_type': args.instance_type,
            'region': region,
            'vpc_id': vpc_id,
            'subnet_id': subnet_id,
        }
        params_dict.update(packer_params or {})

        params_str = ' '.join(f'-var {k}={v}' for k, v in params_dict.items() if v is not None)

        packer_cmd = f'packer build {params_str} {args.template}'
        cmd.logger.debug(packer_cmd)
        exit_code, stdout, stderr = run_in_shell(packer_cmd, args.verbose)
        if exit_code:
            cmd.fail_shell('packer', exit_code, stdout, stderr)

        regex = re.compile(r'AMI: (?P<id>ami-\w+)')
        match = regex.search(stdout)
        if not match:
            cmd.fail('could not find AMI ID in packer output')

        images = cmd.cache.get('images', {})
        images[name] = match.group('id')
        cmd.cache['images'] = images
    finally:
        command_delete_packer_security_group(cmd, args.deployment_name)

    cmd.logger.info('done.')


def command_create_stack(
        cmd, deployment_name, stack_name, template_path, extra_params, wait_period=60):
    cmd.logger.info(f'creating stack {stack_name}...')
    stack_full_name = f'{deployment_name}-{stack_name}'

    # doing this to be compatible with AWS CLI which specifies the template path as
    # file://path/to/template.
    url = urlparse(template_path)
    cmd.logger.debug(f'template: {url.path}')
    with open(url.path) as fh:
        template = fh.read()

    params = [
        {'ParameterKey': 'DeploymentName', 'ParameterValue': deployment_name},
    ]
    params.extend(extra_params)

    cmd.logger.debug(f'using params {params}')
    resp = cmd.aws.cf.create_stack(
        StackName=stack_full_name,
        TemplateBody=template,
        Parameters=params,
        OnFailure='DELETE',
    )
    cmd.logger.debug(f'stack ID: {resp["StackId"]}')

    cmd.logger.info('waiting for the stack creation to complete...')
    resp = cmd.aws.cf.describe_stacks(StackName=stack_full_name)
    while resp['Stacks'][0]['StackStatus'] == 'CREATE_IN_PROGRESS':
        time.sleep(wait_period)
        resp = cmd.aws.cf.describe_stacks(StackName=stack_full_name)

    stack_status = resp['Stacks'][0]['StackStatus']
    if stack_status == 'CREATE_COMPLETE':
        outputs = {}
        for o in resp['Stacks'][0].get('Outputs', []):
            outputs[camel_to_kebab(o['OutputKey'])] = o['OutputValue']
        cmd.cache[stack_name] = outputs

        if outputs:
            cmd.logger.debug('outputs:')
            for k, v in outputs.items():
                cmd.logger.debug(f'    {k}: {v}')

        cmd.logger.info('done.')
    else: # stack_status != 'CREATE_COMPLETE'
        cmd.logger.error(f'creation failed: {stack_status}')
        resp = cmd.aws.cf.describe_stack_events(StackName=stack_full_name)

        for event in resp['StackEvents']:
            if event['ResourceStatus'] != 'CREATE_FAILED':
                continue
            status = event['ResourceStatus']
            reason = event.get("ResourceStatusReason", '')
            cmd.logger.error(f'{status} {reason}')

        cmd.logger.info('waiting for the rollback to complete...')
        resp = cmd.aws.cf.describe_stacks(StackName=stack_full_name)
        while resp['Stacks'][0]['StackStatus'] == 'DELETE_IN_PROGRESS':
            time.sleep(wait_period)
            resp = cmd.aws.cf.describe_stacks(StackName=stack_full_name)

        cmd.fail(f'could not create stack {stack_name}')


def command_connect_sentinel(cmd, user='ubuntu'):
    host = command_get(cmd, 'rds.sentinel-dns-name', 'RDS stack been created')
    key_path = command_get(cmd, 'key.path', 'a key pair been created')
    return fabric.Connection(
        host,
        user=user,
        connect_kwargs={
            'key_filename': key_path,
        },
    )


def command_sentinel(cmd, what, verbose=False, **kwargs):
        flags = ''
        if verbose:
            flags += ' --verbose'
        with command_connect_sentinel(cmd) as con:
            return con.run(f'veraison{flags} {what}', **kwargs)


class DeploymentCache:

    @property
    def dir(self):
        return os.path.dirname(self.path)

    @property
    def certs_dir(self):
        return os.path.join(self.dir, 'certs')

    @property
    def ca_cert_path(self):
        return os.path.join(self.certs_dir, 'rootCA.crt')

    @property
    def ca_key_path(self):
        return os.path.join(self.certs_dir, 'rootCA.key')

    @property
    def user_tag(self):
        return self.db.get('user_tag', self.default_user_tag)

    def __init__(self, name, cache_dir=None):
        if not name:
            raise ValueError('name cannot be empty')
        self.name = name
        if cache_dir is None:
            cache_dir = xdg.BaseDirectory.save_data_path('veraison/aws')
        self.path = os.path.join(cache_dir, f'{self.name}.db')
        self.db = SqliteDict(self.path)
        self.default_user_tag = f'{socket.gethostname()}-{getpass.getuser()}'

    def get(self, key, default=None):
        parts = key.split('.')
        entry = self.db
        path = ''

        try:
            for part in parts[:len(parts)-1]:
                entry = self._access_member(entry, part, path)
                path = path + '.' + part
            return self._access_member(entry, parts.pop(), path)
        except (KeyError, IndexError):
            return default

    def as_dict(self):
        return {k: v for k, v in self.db.items()}

    def close(self):
        self.db.close()

    def _access_member(self, entry, part, path):
        try: # if part is an int, assume list entry
            idx = int(part)
            if (len(entry)-1) > idx:  # pyright: ignore[reportArgumentType]
                if path:
                    raise IndexError(f'{path}.{idx}')
                else:
                    raise IndexError(f'{idx}')
            return entry[idx]
        except ValueError:  # part not an int, assume dict entry
            try:
                return entry[part]
            except KeyError as e:
                if path:
                    raise KeyError(f'{path}.{part}')
                else:
                    raise e

    def __contains__(self, key):
        return key in self.db

    def __setitem__(self, key, value):
        self.db[key] = value
        self.db.commit()

    def __getitem__(self, key):
        return self.db[key]

    def __delitem__(self, key):
        try:
            del self.db[key]
            self.db.commit()
        except KeyError:
            pass


# {{{ commands

class BaseCommand:

    name = None
    desc = None
    aliases = []

    def __init__(self, aws, fail_with_error=True):
        self.aws = aws
        self.logger = logging.getLogger(self.name)
        self.fail_with_error = fail_with_error
        self.cache = None

    def register(self, subparsers):
        parser = subparsers.add_parser(self.name, help=self.desc, aliases=self.aliases)
        self.update_arguments(parser)

    def execute(self, args):
        if args.verbose and args.quiet:
            self.fail('only one of -v/--verbose or -q/--quiet may be specfied at a time')
        if args.verbose:
            self.logger.setLevel(logging.DEBUG)
        elif args.quiet:
            self.logger.setLevel(logging.WARNING)

        self.cache = DeploymentCache(args.deployment_name, args.cache_dir)
        try:
            self.run(args)
        finally:
            self.cache.close()

    def fail(self, message):
        write = self.logger.error if self.fail_with_error else self.logger.info
        write(message)
        raise RuntimeError(f'command {self.name} failed.')

    def fail_shell(self, command, exit_code, stdout, stderr):
        stdout_file = f'/tmp/{args.deployment_name}-{command}-failure.stdout'
        with open(stdout_file, 'w') as wfh:
            wfh.write(stdout)

        stderr_file = f'/tmp/{args.deployment_name}-{command}-failure.stderr'
        with open(stderr_file, 'w') as wfh:
            wfh.write(stderr)

        self.fail(f'{command} failed with {exit_code}'
                  f'\n\tSTDOUT is in {stdout_file}\n\tSTDERR is in {stderr_file}')

    def update_arguments(self, parser):
        pass

    def run(self, *args, **kwargs):
        raise NotImplementedError()


class CreateRdsStackCommand(BaseCommand):

    name = 'create-rds-stack'
    desc = 'create deployment\'s cloudformation stack running RDS instance'

    def run(self, args):
        template_path = os.path.abspath(os.path.join(
            os.path.dirname(__file__),
            '../templates/stack-rds.yaml',
        ))

        vpc_cidr = command_get_config(self, 'vpc-cidr')
        admin_cidr = command_get_config(self, 'admin-cidr')
        key_name = command_get(self, 'key.name', 'a key pair been created')
        vpc_id = command_get(self, 'vpc.vpc-id', 'VPC stack been created')
        dns_name = command_get_config(self, 'dns-name')
        hz_id = command_get_hosted_zone(self, dns_name)
        sentinel_image = command_get(self, 'images.sentinel', 'sentinel image been created')
        public_subnet = command_get(self, 'vpc.public-subnet-a-id', 'VPC stack been created')
        rds_subnets = [
            self.cache.get('vpc.private-subnet-a-id'),
            self.cache.get('vpc.private-subnet-b-id'),
        ]


        self.logger.debug('generating admin password for Postgres and writing into cache...')
        # note: not using punctuation in the initial password, as it will be passed through
        # multiple shells, environments, and tools, and we don't want to
        # warry about correctrly escaping everything at every stage. Using a longer string
        # to compensate.
        password = randomword(40)
        self.cache['postgres_admin_password'] = password

        extra_params = [
            {'ParameterKey': 'VpcId', 'ParameterValue': vpc_id},
            {'ParameterKey': 'KeyName', 'ParameterValue': key_name},
            {'ParameterKey': 'SubnetCidr', 'ParameterValue': vpc_cidr},
            {'ParameterKey': 'RdsSubnets', 'ParameterValue': ','.join(rds_subnets)},  # pyright: ignore
            {'ParameterKey': 'RdsPassword', 'ParameterValue': password},  # pyright: ignore
            {'ParameterKey': 'KeyName', 'ParameterValue': key_name},
            {'ParameterKey': 'PublicSubnet', 'ParameterValue': public_subnet},
            {'ParameterKey': 'ParentDomain', 'ParameterValue': dns_name},
            {'ParameterKey': 'HostedZoneId', 'ParameterValue': hz_id},
            {'ParameterKey': 'SentinelImage', 'ParameterValue': sentinel_image},
            {'ParameterKey': 'AdminCidr', 'ParameterValue': admin_cidr},
        ]

        command_create_stack(cmd, args.deployment_name, 'rds',
                             template_path, extra_params, args.wait_period)


class CreateServicesStackCommand(BaseCommand):

    name = 'create-services-stack'
    desc = '''create deployment\'s CloudFormation stack running Veraison services
           on auto-scaled instances'''

    def run(self, args):
        template_path = os.path.abspath(os.path.join(
            os.path.dirname(__file__),
            '../templates/stack-services.yaml',
        ))

        region = command_get_config(self, 'region')
        dns_name = command_get_config(self, 'dns-name')
        ports = command_get_config(self, 'ports')
        scaling = command_get_config(self, 'scaling')
        hz_id = command_get_hosted_zone(self, dns_name)
        admin_cidr = command_get_config(self, 'admin-cidr')
        key_name = command_get(self, 'key.name', 'a key pair been created')
        services_image = command_get(self, 'images.services', 'services image been created')
        keycloak_image = command_get(self, 'images.keycloak', 'keycloak image been created')
        vpc_id = command_get(self, 'vpc.vpc-id', 'VPC stack been created')
        pub_subnet_a_id = command_get(self, 'vpc.public-subnet-a-id', 'VPC stack been created')
        pub_subnet_b_id = command_get(self, 'vpc.public-subnet-b-id', 'VPC stack been created')
        pub_subnet_a_cidr = command_get(self, 'vpc.public-subnet-a-cidr',
                                        'VPC stack been created')
        pub_subnet_b_cidr = command_get(self, 'vpc.public-subnet-b-cidr',
                                        'VPC stack been created')
        priv_subnet_a_id = command_get(self, 'vpc.private-subnet-a-id', 'VPC stack been created')
        priv_subnet_b_id = command_get(self, 'vpc.private-subnet-b-id', 'VPC stack been created')

        self.logger.debug(f'looking up certificate for {dns_name}...')
        cert_arn = None
        resp = self.aws.acm.list_certificates(CertificateStatuses=['ISSUED'])
        for cert_summary in resp['CertificateSummaryList']:
            if cert_summary['DomainName'] == dns_name:
                cert_arn = cert_summary['CertificateArn']
                break
        else:
            self.fail(f'Could not find certificate for {dns_name}')

        extra_params = [
            {'ParameterKey': 'VpcId', 'ParameterValue': vpc_id},
            {'ParameterKey': 'AdminCidr', 'ParameterValue': admin_cidr},
            {'ParameterKey': 'KeyName', 'ParameterValue': key_name},
            {'ParameterKey': 'CombinedImage', 'ParameterValue': services_image},
            {'ParameterKey': 'PublicSubnetA', 'ParameterValue': pub_subnet_a_id},
            {'ParameterKey': 'PublicSubnetB', 'ParameterValue': pub_subnet_b_id},
            {'ParameterKey': 'PublicSubnetACidr', 'ParameterValue': pub_subnet_a_cidr},
            {'ParameterKey': 'PublicSubnetBCidr', 'ParameterValue': pub_subnet_b_cidr},
            {'ParameterKey': 'PrivateSubnetA', 'ParameterValue': priv_subnet_a_id},
            {'ParameterKey': 'PrivateSubnetB', 'ParameterValue': priv_subnet_b_id},

            {'ParameterKey': 'ServiceCidr', 'ParameterValue': admin_cidr},
            {'ParameterKey': 'Region', 'ParameterValue': region},

            {'ParameterKey': 'ParentDomain', 'ParameterValue': dns_name},
            {'ParameterKey': 'HostedZoneId', 'ParameterValue': hz_id},
            {'ParameterKey': 'CertificateArn', 'ParameterValue': cert_arn},
            {'ParameterKey': 'KeycloakImage', 'ParameterValue': keycloak_image},

            {'ParameterKey': 'ProvisioningPort', 'ParameterValue': str(ports['provisioning'])},
            {'ParameterKey': 'VerificationPort', 'ParameterValue': str(ports['verification'])},
            {'ParameterKey': 'ManagementPort', 'ParameterValue': str(ports['management'])},
            {'ParameterKey': 'KeycloakPort', 'ParameterValue': str(ports['keycloak'])},

            {'ParameterKey': 'ScalingMinSize', 'ParameterValue': str(scaling['min-size'])},
            {'ParameterKey': 'ScalingMaxSize', 'ParameterValue': str(scaling['max-size'])},
            {'ParameterKey': 'ScalingCpuUtilTarget',
             'ParameterValue': str(scaling['cpu-util-target'])},
            {'ParameterKey': 'ScalingRequestCountTarget',
             'ParameterValue': str(scaling['request-count-target'])},
        ]

        command_create_stack(cmd, args.deployment_name, 'services',
                             template_path, extra_params, args.wait_period)


class DeleteStackCommand(BaseCommand):

    name = 'delete-stack'
    desc = 'delete a previously created stack'

    def update_arguments(self, parser):
        parser.add_argument('name')

    def run(self, args):
        stack_full_name = f'{args.deployment_name}-{args.name}'
        self.logger.info(f'deleting stack {stack_full_name}...')

        self.aws.cf.delete_stack(StackName=stack_full_name)
        try:
            self.logger.debug('waiting for the stack deletion to complete...')
            resp = self.aws.cf.describe_stacks(StackName=stack_full_name)
            while resp['Stacks'][0]['StackStatus'] == 'DELETE_IN_PROGRESS':
                time.sleep(args.wait_period)
                resp = self.aws.cf.describe_stacks(StackName=stack_full_name)
        except ClientError as e:
            if 'does not exist' not in str(e):
                raise e

        del self.cache[args.name]

        self.logger.info('done.')


class UpdateSecurityGroupsCommand(BaseCommand):

    name = 'update-security-groups'
    desc = 'update security group(s) in deployment with current host\'s IP address'

    def update_arguments(self, parser):
        parser.add_argument('-p', '--ports', action=StoreIntList,
                            default=[11111, 8888, 8088, 8080, 5432, 22])

    def run(self, args):
        self.logger.info('updating deployment security groups with IP address for this host...')

        names = [
            f'{args.deployment_name}-sentinel-intance-sg'
        ]

        try:
            command_update_dynamic_address_rules(
                    self, args.deployment_name, names, self.cache.user_tag, args.ports)
        except Exception as e:
            self.fail(e)

        self.logger.info('done.')


class CreateServicesImageCommand(BaseCommand):

    name = 'create-services-image'
    desc = 'create IMA image for the Veraison services EC2 instances'

    def update_arguments(self, parser):
        parser.add_argument('-D', '--deb')
        parser.add_argument(
                '-c', '--services-config-template',
            default=os.path.abspath(os.path.join(
                os.path.dirname(__file__),
                '../templates/services-config.yaml.template',
            )),
        )
        parser.add_argument(
            '-t', '--template',
            default=os.path.abspath(os.path.join(
                os.path.dirname(__file__),
                '../templates/image-services.pkr.hcl',
            )),
        )
        parser.add_argument('-T', '--instance-type')

    def run(self, args):
        deb_path = args.deb or self.cache['deb']
        if not os.path.isfile(deb_path):
            self.fail(f'{deb_path} does not exist')
        self.cache['deb'] = deb_path

        ports = command_get_config(self, 'ports')
        rds = command_get(self, 'rds', 'RDS stack has been created')
        password = command_get(self, 'postgres_admin_password', 'RDS stack has been created')
        os.environ['RDS_HOST'] = rds['host']
        os.environ['RDS_PORT'] = rds['port']
        os.environ['RDS_DBNAME'] = 'veraison'
        os.environ['RDS_USER'] = 'veraison'
        os.environ['RDS_PASSWORD'] = password # pyright: ignore
        os.environ['VTS_PORT'] = str(ports['vts'])
        os.environ['PROVISIONING_PORT'] = str(ports['provisioning'])
        os.environ['VERIFICATION_PORT'] = str(ports['verification'])
        os.environ['MANAGEMENT_PORT'] = str(ports['management'])
        os.environ['VTS_PORT'] = str(ports['vts'])
        os.environ['KEYCLOAK_PORT'] = str(ports['keycloak'])

        config_path = command_instantiate_template(
                self, args.deployment_name, args.services_config_template,
                self.cache.dir)
        self.cache['services_config_file'] = config_path

        command_create_image(self, args, 'services',
                             {
                                 'deb': deb_path,
                                 'config_path': config_path,
                             })


class RegisterDomainCommand(BaseCommand):

    name = 'register-domain'
    desc = 'delete a previously created stack'

    def update_arguments(self, parser):
        parser.add_argument('domain', help='domain to be registred')
        parser.add_argument('-a', '--autorenew', action='store_true',
                            help='domain will autorenew upon expiration if this is specified')
        parser.add_argument('-d' '--duration-in-years', type=int, default=1,
                            help='duration of the registration in years')

    def run(self, args):
        stack_name = f'{args.deployment_name}-{args.name}'
        self.logger.info(f'deleting stack {stack_name}...')


class ConfigureCommand(BaseCommand):

    name = 'configure'
    desc = 'configure deployment parameters'

    default_provisioning_user = 'veraison-provisioner'
    default_provisioning_password = 'veraison'
    default_management_user = 'veraison-manager'
    default_management_password = 'veraison'
    default_client_id = 'veraison-client'
    default_client_secret = 'YifmabB4cVSPPtFLAmHfq7wKaEHQn10Z'
    default_scaling_min_size = 1
    default_scaling_max_size = 3
    default_scaling_cpu_util_target = 60
    default_scaling_request_count_target = 10

    def update_arguments(self, parser):
        parser.add_argument('-i', '--init', action='store_true',
                            help='indiates that this is an initial configuration for a '
                            'deployment; if a parameter is not specified, its default value '
                            'will be configured, if it has one, or an error will be raised '
                            'otherwise')

        parser.add_argument('-a', '--admin-cidr',
                            help='CIDR for IP address that will be allowed access to the '
                                 'sentinel instance')
        parser.add_argument('-c', '--vpc-cidr',
                            help='CIDR used for the VPC; this should be large ennough to '
                                 'accommodate four subnets (recommended at least /16).')
        parser.add_argument('-d', '--dns-name',
                            help='parent domain that will be used for the deployment; it must '
                                 'be registered in Route53')
        parser.add_argument('-r', '--region',
                            help='AWS region inside which the deployment will be created')

        parser.add_argument('-P', '--provisioning-port' , type=Port,
                            help='port that will be used for the provisioning service')
        parser.add_argument('-V', '--verification-port' , type=Port,
                            help='port that will be used for the verification service')
        parser.add_argument('-M', '--management-port' , type=Port,
                            help='port that will be used for the management service')
        parser.add_argument('-K', '--keycloak-port' , type=Port,
                            help='port that will be used for Keycloak')
        parser.add_argument('-X', '--vts-port' , type=Port,
                            help='port that will be used for the VTS service (note: '
                                 'currently, VTS runs on the same instance as a front-end '
                                 'service so this is largely irrelevant)')

        parser.add_argument('-p', '--provisioning-user',
                            help='the name of provisioning user; must match Keycloak realm')
        parser.add_argument('-R', '--provisioning-password',
                            help='the password of provisioning user; must match Keycloak realm')
        parser.add_argument('-m', '--management-user',
                            help='the name of management user; must match Keycloak realm')
        parser.add_argument('-Q', '--management-password',
                            help='the password of management user; must match Keycloak realm')
        parser.add_argument('-C', '--client-id',
                            help='client ID used to connect to Keycloak API')
        parser.add_argument('-S', '--client-secret',
                            help='client SECRET used to connect to Keycloak API')

        parser.add_argument('-A', '--keycloak-admin',
                            help='the name of Keycloak instance admin account')
        parser.add_argument('-U', '--keycloak-version',
                            help='verision of Keycloak that will be used in the deployment')

        parser.add_argument('-I', '--scaling-min-size', type=int,
                            help='minimum number of instances inside an auto-scaling group')
        parser.add_argument('-J', '--scaling-max-size', type=int,
                            help='maximum number of instances inside an auto-scaling group')
        parser.add_argument('-D', '--scaling-cpu-util-target', type=Percent,
                            help='CPU utilization that will be targed by auto-scaling policies')
        parser.add_argument('-E', '--scaling-request-count-target', type=int,
                            help='request count that will be targed by auto-scaling policies')

    def run(self, args):
        self._configure_region(args)
        self._configure_admin_cidr(args)
        self._configure_vpc_cidr(args)
        self._configure_client_settings(args)
        self._configure_dns_name(args)
        self._configure_ports(args)
        self._configure_keycloak(args)
        self._configure_scaling(args)

    def _configure_admin_cidr(self, args):
        if args.admin_cidr:
            self.cache['admin-cidr'] = args.admin_cidr
        elif args.init:
            self.logger.warning('setting admin CIDR to 0.0.0.0/0; this is not recommended: '
                                're-run with --admin-cidr option')
            self.cache['admin-cidr'] = '0.0.0.0/0'

    def _configure_vpc_cidr(self, args):
        if args.vpc_cidr:
            self.cache['vpc-cidr'] = args.vpc_cidr
        elif args.init:
            self.logger.info('defaulting VPC CIDR to 10.0.0.0/16 '
                             '(re-run with --vpc-cidr to change)')
            self.cache['admin-cidr'] = '10.0.0.0/16'

    def _configure_client_settings(self, args):
        attrs =  [
            'provisioning_user',
            'provisioning_password',
            'management_user',
            'management_password',
            'client_id',
            'client_secret',
        ]

        if args.init:
            for attr in attrs:
                default = getattr(self.__class__, f'default_{attr}')
                setattr(args, attr, getattr(args, attr) or default)

        client_config = self.cache.get('client_config', {})

        for attr in attrs:
            new_val = getattr(args, attr)
            if new_val:
                client_config[attr] = new_val

        self.cache['client_config'] = client_config

    def _configure_dns_name(self, args):
        if args.dns_name:
            self.logger.debug(f'writing {args.dns_name} to cache')
            self.cache['dns-name'] = args.dns_name
        elif args.init:
            raise ValueError('--dns-name not specified; it must be configured')

    def _configure_region(self, args):
        if args.region:
            self.logger.debug(f'writing {args.region} to cache')
            self.cache['region'] = args.region
            return
        elif not args.init and self.cache.get('region'):
            return  # already set and not re-initializing

        subnet_id = command_get_config(self, 'subnet-id')

        resp = self.aws.ec2.describe_subnets(SubnetIds=[subnet_id])
        zone_id = resp['Subnets'][0]['AvailabilityZoneId']

        resp = self.aws.ec2.describe_availability_zones(ZoneIds=[zone_id])
        region = resp['AvailabilityZones'][0]['RegionName']

        self.cache['region'] = region

    def _configure_ports(self, args):
        names = ['vts', 'keycloak', 'provisioning', 'verification', 'management']
        ports = self.cache.get('ports', {})

        for name in names:
            val = getattr(args, f'{name}_port', None)
            if val is not None:
                ports[name] = int(val)
            elif args.init:
                raise ValueError(f'--{name}-port not specified; it must be configured')

        self.logger.debug('writing ports to cache...')
        self.cache['ports'] = ports

    def _configure_keycloak(self, args):
        if args.keycloak_version:
            self.cache['keycloak-version'] = args.keycloak_version
        elif args.init:
            self.logger.info('setting keycloak version to 25.0.5; '
                             'use --keycloak-version to change')
            self.cache['keycloak-version'] = '25.0.5'

        if args.keycloak_admin:
            self.cache['keycloak-admin'] = args.keycloak_admin
        elif args.init:
            self.logger.info('setting keycloak admin account name to "admin"; '
                             'use --keycloak-admin to change')
            self.cache['keycloak-admin'] = 'admin'

    def _configure_scaling(self, args):
        arg_names = [
            'scaling-min-size',
            'scaling-max-size',
            'scaling-cpu-util-target',
            'scaling-request-count-target',
        ]
        scaling = self.cache.get('scaling', {})

        for name in arg_names:
            attr = name.replace('-', '_')
            val = getattr(args, attr)
            if val:
                scaling[name.replace('scaling-', '')] = val
            elif args.init:
                default = getattr(self, f'default_{attr}', None)
                if default:
                    self.logger.info(f'setting {name.replace('-', ' ')} to {default}; '
                                     f'use --{name} to change')
                    scaling[name.replace('scaling-', '')] = default
                else:
                    self.fail(f'--{name} must be specified')

        self.logger.debug('writing scaling config...')
        self.cache['scaling'] = scaling


class CreateKeycloakImageCommand(BaseCommand):

    name = 'create-keycloak-image'
    desc = 'create IMA image for the Keycloak EC2 instance'

    def update_arguments(self, parser):
        parser.add_argument(
                '-c', '--keycloak-conf-template',
            default=os.path.abspath(os.path.join(
                os.path.dirname(__file__),
                '../templates/keycloak.conf.template',
            )),
        )
        parser.add_argument(
                '-s', '--keycloak-service-template',
            default=os.path.abspath(os.path.join(
                os.path.dirname(__file__),
                '../templates/keycloak.service.template',
            )),
        )
        parser.add_argument(
            '-t', '--template',
            default=os.path.abspath(os.path.join(
                os.path.dirname(__file__),
                '../templates/image-keycloak.pkr.hcl',
            )),
        )
        parser.add_argument(
            '-r', '--realm-file',
            default=os.path.abspath(os.path.join(
                os.path.dirname(__file__),
                '../misc/veraison-realm.json',
            )),
        )
        parser.add_argument('-T', '--instance-type')

    def run(self, args):
        if not os.path.isfile(args.realm_file):
            self.fail(f'realm file {args.realm_file} does not exist')

        self.logger.debug('generating admin password for Keycloak and writing into cache...')
        # note: not using punctuation in the initial password, as it will be passed through
        # multiple shells, environments, and tools, and we don't want to
        # warry about correctrly escaping everything at every stage. Using a longer string
        # to compensate.
        password = randomword(40)
        os.environ['KEYCLOAK_ADMIN_PASSWORD'] = password
        self.cache['keycloak_admin_password'] = password

        rds = command_get(self, 'rds', 'RDS stack has been created')
        password = command_get(self, 'postgres_admin_password', 'RDS stack has been created')

        os.environ['RDS_HOST'] = rds['host']
        os.environ['RDS_PORT'] = rds['port']
        os.environ['RDS_USER'] = 'veraison'
        os.environ['RDS_PASSWORD'] = password  # pyright: ignore

        conf_path = command_instantiate_template(
                self, args.deployment_name, args.keycloak_conf_template)
        service_path = command_instantiate_template(
                self, args.deployment_name, args.keycloak_service_template)

        command_create_image(self, args, 'keycloak',
                             {
                                 'conf_path': conf_path,
                                 'service_path': service_path,
                                 'realm_path': args.realm_file,
                             })


class CreateSentinelImageCommand(BaseCommand):

    name = 'create-sentinel-image'
    desc = 'create IMA image for the sentinel EC2 instance'

    def update_arguments(self, parser):
        parser.add_argument(
            '-t', '--template',
            default=os.path.abspath(os.path.join(
                os.path.dirname(__file__),
                '../templates/image-sentinel.pkr.hcl',
            )),
        )
        parser.add_argument(
            '-d', '--dispatcher',
            default=os.path.abspath(os.path.join(
                os.path.dirname(__file__),
                '../misc/sentinel-commands',
            )),
        )
        parser.add_argument('-T', '--instance-type')

    def run(self, args):
        command_create_image(self, args, 'sentinel',
                             {
                                 'command_dispatcher_path': args.dispatcher,
                             })


class DeleteImageCommand(BaseCommand):

    name = 'delete-image'
    desc = 'delete IMA image for the Veraison services EC2 instance'

    def update_arguments(self, parser):
        parser.add_argument('name')

    def run(self, args):
        images = self.cache.get('images', {})
        iid = images.get(args.name)
        if iid is None:
            self.fail(f'no entry for image {args.name} found in the deployment cache')

        self.logger.info(f'deleting image {args.name} ({iid})...')
        self.aws.ec2.deregister_image(ImageId=iid)

        self.logger.debug(f'removing image {args.name} from cache')
        del images[args.name]
        self.cache['images'] = images

        self.logger.info('done.')


class CreateKeyPairCommand(BaseCommand):

    name = 'create-key-pair'
    desc = 'create a key pair that will be used for SSH access to the deployment\'s instances'

    def update_arguments(self, parser):
        parser.add_argument('-n', '--key-name')
        parser.add_argument('-t', '--key-type', choices=['rsa', 'ed25519'], default='rsa')

    def run(self, args):
        key_info = self.cache.get('key')
        if key_info:
            self.fail(f'key pair for {args.deployment_name} already exits: '
                      f'{key_info['name']} ({key_info['id']})')

        name = args.key_name or os.getenv('VERAISON_AWS_KEY') or args.deployment_name

        self.logger.info(f'creating key pair {name} for {args.deployment_name}...')
        resp = aws.ec2.create_key_pair(
            KeyName=name,
            KeyType=args.key_type,
            KeyFormat='pem',
            TagSpecifications=[
                {
                    'ResourceType': 'key-pair',
                    'Tags': [
                        {'Key': 'veraison-deployment', 'Value': args.deployment_name},
                    ],
                }
            ],
        )

        path = os.path.join(self.cache.dir, f'{name}_{args.key_type}')
        self.logger.info(f'writing private key to {path}')
        with open(path, 'w') as wfh:
            wfh.write(resp['KeyMaterial'])
        os.chmod(path, stat.S_IRUSR | stat.S_IWUSR)

        self.cache['key'] ={
            'name': name,
            'id': resp['KeyPairId'],
            'fingerprint': resp['KeyFingerprint'],
            'path': path,
        }

        self.logger.info('done.')


class DeleteKeyPairCommand(BaseCommand):

    name = 'delete-key-pair'
    desc = 'create a key pair that will be used for SSH access to the deployment\'s instances'

    def run(self, args):
        self.logger.info(f'deleting key pair for {args.deployment_name}...')
        key_info = self.cache.get('key')
        if key_info:
            if os.path.isfile(key_info['path']):
                self.logger.debug(f'deleting {key_info['path']}')
                os.remove(key_info['path'])
            else:
                self.logger.debug(f'{key_info['path']} not found (already deleted?)')
            self.logger.debug(f'deleting AWS key pair {key_info['name']} ({key_info['id']})')
            self.aws.ec2.delete_key_pair(KeyPairId=key_info['id'])
            del self.cache['key']
            self.logger.info('done.')
        else:
            self.logger.debug('no key info cached; checking VERAISON_AWS_KEY')
            key_name = os.getenv('VERAISON_AWS_KEY')
            if key_name:
                self.logger.debug(f'deleting AWS key pair {key_name}')
                self.aws.ec2.delete_key_pair(KeyName=key_name)
            else:
                self.logger.debug('VERAISON_AWS_KEY not specified; search for key '
                                  f'tagged with {args.deployment_name}')
                resp = self.aws.ec2.describe_key_pairs(
                    Filters=[{
                        'Name': 'tag:veraison-deployment',
                        'Values': [
                            args.deployment_name,
                        ],
                    }],
                )

                if len(resp['KeyPairs']) == 1:
                    name = resp['KeyPairs'][0]['KeyName']
                    kid = resp['KeyPairs'][0]['KeyPairId']
                    self.logger.debug(f'deleting AWS key pair {name} ({kid})')
                    self.aws.ec2.delete_key_pair(KeyPairId=kid)
                else:
                    if len(resp['KeyPairs']) > 1:
                        names = ', '.join([kp['KeyName'] for kp in resp['KeyPairs']])
                        self.logger.debug(f'multiple key pairs for {args.deployment_name} found '
                                          f'({names}). Specify key name using VERAISON_AWS_KEY')
                    else:
                        self.logger.debug(f'no key pairs found for {args.deployment_name}')

                    self.fail(f'could not delete key pair for {args.deployment_name}')

            self.logger.info('done. (local files not touched)')


class CreateDebCommand(BaseCommand):

    name = 'create-deb'
    desc = 'create the Veraison Debian package'

    def update_arguments(self, parser):
        parser.add_argument(
            '-s', '--veraison-src',
            help='path to Veraison services source; if not specified, '
                 'it will be guess based on this script\'s location',
        )
        parser.add_argument(
            '-w', '--work-dir', default='/tmp',
            help='this will be used as the working directory when creating the .deb. '
                 'Upon completion, t will contain the intermediate artifacts.',
        )

    def run(self, args):
        src_root = args.veraison_src
        if src_root is None:
            src_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../..'))

        script = os.path.join(src_root, 'deployments/debian/deployment.sh')
        if not os.path.isfile(script):
            self.fail(f'script {script} does not exist')

        self.logger.info(f'creating Debian package under {args.work_dir}...')
        create_deb_cmd = f'{script} create-deb {args.work_dir}'
        self.logger.debug(create_deb_cmd)
        exit_code, stdout, stderr = run_in_shell(create_deb_cmd, args.verbose)
        if exit_code:
            self.fail_shell('deb creation', exit_code, stdout, stderr)

        regex = re.compile(r"building package 'veraison' in '(?P<deb_path>[^']+)'")
        match = regex.search(stdout)
        if not match:
            self.fail(f'could not find deb path in script output')

        deb_path = match.group('deb_path')
        dest_path = os.path.join(args.cache_dir, os.path.basename(deb_path))
        self.logger.debug(f'moving {deb_path} to {dest_path}')
        shutil.move(deb_path, dest_path)

        self.logger.debug('updating deployment cache')
        self.cache['deb'] = dest_path

        self.logger.info(f'created {dest_path}')

        self.logger.info('done.')


class DeleteDebCommand(BaseCommand):

    name = 'delete-deb'
    desc = 'delete perviously created Debian package'

    def run(self, args):
        self.logger.info('deleting cached Debian package...')

        deb_path = self.cache.get('deb')
        if not deb_path:
            self.logger.info('could not find deb in cache; nothing to do.')
            return

        self.logger.debug(f'removing deb {deb_path}')
        os.remove(deb_path)
        del self.cache['deb']

        self.logger.info('done.')


class CreateVpcStack(BaseCommand):
    name = 'create-vpc-stack'
    desc = 'create stack setting up the VPC, subnets and associated routing for Veraison services'

    def run(self, args):
        region = self.cache.get('region')
        if not region:
            self.fail('region has not been configured')

        cidr_block = self.cache.get('vpc-cidr')
        if not cidr_block:
            self.fail('VPC CIDR block has not been configured')

        template_path = os.path.abspath(os.path.join(
            os.path.dirname(__file__),
            '../templates/stack-vpc.yaml',
        ))

        extra_params = [
            {'ParameterKey': 'Region', 'ParameterValue': region},
            {'ParameterKey': 'VpcCidrBlock', 'ParameterValue': cidr_block},
        ]

        command_create_stack(cmd, args.deployment_name, 'vpc',
                             template_path, extra_params, args.wait_period)


class ShellCommand(BaseCommand):

    name = 'shell'
    desc = 'start a shell on the sentinel instance'

    def update_arguments(self, parser):
        parser.add_argument('-s', '--server-alive-interval', type=int, default=60)

    def run(self, args):
        if not shutil.which('ssh'):
            self.fail('ssh does not appear to be installed on the system')

        host = command_get(self, 'rds.sentinel-dns-name', 'RDS stack been created')
        key = command_get(self, 'key.path', 'a key pair been created')

        ssh_opts = '-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null'
        if args.server_alive_interval:
            ssh_opts += f' -o ServerAliveInterval={args.server_alive_interval}'

        ssh_cmd = f'ssh {ssh_opts} -i {key} ubuntu@{host}'
        self.logger.debug(ssh_cmd)
        os.system(ssh_cmd)


class DbShellCommand(BaseCommand):

    name = 'dbshell'
    desc = 'start a database shell on a deployment\'s RDS instance'

    def update_arguments(self, parser):
        parser.add_argument('-s', '--server-alive-interval', type=int, default=60)

    def run(self, args):
        if not shutil.which('ssh'):
            self.fail('ssh does not appear to be installed on the system')

        rds = command_get(self, 'rds', 'RDS stack has been created')
        pgpass = command_get(self, 'postgres_admin_password', 'RDS stack has been created')
        psql_cmd = f'PGPASSWORD={pgpass} psql -h {rds['host']} -p {rds['port']} '\
                   f'-U veraison -d veraison'

        host = command_get(self, 'rds.sentinel-dns-name', 'RDS stack been created')
        key = command_get(self, 'key.path', 'a key pair been created')

        ssh_opts = '-t -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null'
        if args.server_alive_interval:
            ssh_opts += f' -o ServerAliveInterval={args.server_alive_interval}'

        ssh_cmd = f'ssh {ssh_opts} -i {key} ubuntu@{host} "{psql_cmd}"'
        self.logger.debug(ssh_cmd)
        os.system(ssh_cmd)


class CreateClientConfigCommand(BaseCommand):

    name = 'create-client-config'
    desc = '''
    create configuration for Veraison clients to access the deployment
    '''
    all_clients = ['cocli', 'evcli', 'pocli']

    def update_arguments(self, parser):
        parser.add_argument('-c', '--client',
                            action='append', dest='clients', choices=self.all_clients)
        parser.add_argument('-o', '--output-dir', default=xdg.BaseDirectory.xdg_config_home)

    def run(self, args):
        self.logger.info('creating Veraison client config(s)...')
        client_config = self.cache.get('client_config')
        if not client_config:
            self.fail('client config not found; run configure command with appropriate options')

        dns_name = self.cache.get('dns-name')
        if not dns_name:
            self.fail('DNS name not found; run configure command ensuring VERAISON_AWS_DNS_NAME '
                      'environment variable is set (and exported)')
        host = f'services.{dns_name}'

        services_config_path = self.cache.get('services_config_file')
        if not services_config_path:
            self.fail('services config not found; re-create the services image')

        with open(services_config_path, 'r') as fh:
            srv_cfg = yaml.safe_load(fh)

        kc_host = srv_cfg.get('auth', {}).get('host')
        kc_port = srv_cfg.get('auth', {}).get('port')
        if not (kc_host and kc_port):
            self.fail('keycloak host/port not found in services config; '
                      'has auth been configured?')

        clients = args.clients or self.all_clients
        for client in clients:
            self.logger.info(f'generating {client} config...')
            outdir = os.path.join(args.output_dir, client)
            if not os.path.isdir(outdir):
                self.logger.debug(f'creating {outdir}')
                os.makedirs(outdir)

            config = getattr(self, f'get_{client}_config')(
                srv_cfg, client_config, host, kc_host, kc_port,
            )

            outfile = os.path.join(outdir, 'config.yaml')
            self.logger.debug(f'writing {outfile}')
            with open(outfile, 'w') as wfh:
                yaml.dump(config, wfh)

            self.cache['client_config_dir'] = args.output_dir
            self.logger.info('done.')

    def get_cocli_config(self, srv_cfg, cli_cfg, host, kc_host, kc_port):
        port = int(srv_cfg['provisioning']['listen-addr'].split(':')[1])
        return {
            'api_server': f'https://{host}:{port}/endorsement-provisioning/v1/submit',
            'auth': 'oauth2',
            'username': cli_cfg['provisioning_user'],
            'password': cli_cfg['provisioning_password'],
            'client_id': cli_cfg['client_id'],
            'client_secret': cli_cfg['client_secret'],
            'token_url': f'https://{kc_host}:{kc_port}'
                          '/realms/veraison/protocol/openid-connect/token',
        }

    def get_evcli_config(self, srv_cfg, cli_cfg, host, kc_host, kc_port):
        port = int(srv_cfg['verification']['listen-addr'].split(':')[1])
        return {
            'api_server': f'https://{host}:{port}/challenge-response/v1/newSession',
        }

    def get_pocli_config(self, srv_cfg, cli_cfg, host, kc_host, kc_port):
        port = int(srv_cfg['management']['listen-addr'].split(':')[1])
        return {
            'tls': True,
            'host': host,
            'port': port,
            'auth': 'oauth2',
            'username': cli_cfg['management_user'],
            'password': cli_cfg['management_password'],
            'client_id': cli_cfg['client_id'],
            'client_secret': cli_cfg['client_secret'],
            'token_url': f'https://{kc_host}:{kc_port}'
                          '/realms/veraison/protocol/openid-connect/token',
        }


class CacheCommand(BaseCommand):

    name = 'cache'
    desc = 'show cached info for the deployment'

    def update_arguments(self, parser):
        parser.add_argument('-q', '--query',
                            help='a dot-separated path for the entry the value of which is '
                                 'to be displayed; if not specified, the entrie cache will be '
                                 'shown')
        parser.add_argument('-d', '--delete',
                            help='the key to be deleted (note: dot-spearated paths not supported')

    def run(self, args):
        if args.query:
            val = self.cache.get(args.query)
            if val is not None:
                sys.stdout.write(val)
        elif args.delete:
            del self.cache[args.delete]
        else:
            print(f'deployment: {args.deployment_name}')
            pprint.pp(self.cache.as_dict())


class SetupRdsCommand(BaseCommand):

    name = 'setup-rds'
    desc = 'setup the RDS instance for use as a K-V store for the services'

    def run(self, args):
        rds = command_get(self, 'rds', 'RDS stack has been created')
        password = command_get(self, 'postgres_admin_password', 'RDS stack has been created')
        res = command_sentinel(
            self,
            f'setup-rds {rds['host']} {rds['port']} {password}',
            verbose=args.verbose, echo=False, hide=False, pty=True,
        )
        if res.exited != 0:
            self.fail(f'could not set up stores; got {res.exited}: {res.stdout}')


class CheckStoresCommand(BaseCommand):

    name = 'check-stores'
    desc = 'output the contents of deployment\'s sqlite3 stores'
    aliases = ['stores']

    def run(self, args):
        rds = command_get(self, 'rds', 'RDS stack has been created')
        password = command_get(self, 'postgres_admin_password', 'RDS stack has been created')
        res = command_sentinel(
            self,
            f'check-stores {rds['host']} {rds['port']} {password}',
            verbose=args.verbose, echo=False, hide=False, pty=True,
        )
        if res.exited != 0:
            self.fail(f'could not check stores; got {res.exited}: {res.stdout}')


class ClearStoresCommand(BaseCommand):
    name = 'clear-stores'
    desc = 'clear the contents of deployment\'s sqlite3 stores'

    def run(self, args):
        rds = command_get(self, 'rds', 'RDS stack has been created')
        password = command_get(self, 'postgres_admin_password', 'RDS stack has been created')
        res = command_sentinel(
            self,
            f'clear-stores {rds['host']} {rds['port']} {password}',
            verbose=args.verbose, echo=False, hide=False, pty=True,
        )
        if res.exited != 0:
            self.fail(f'could not clear stores; got {res.exited}: {res.stdout}')


class StatusCommand(BaseCommand):

    name = 'status'
    desc = 'show status of the deployment'

    def run(self, args):
        print(f'deployment: {args.deployment_name}')
        print()

        print('images:')
        images = self.cache.get('images', {})
        if 'keycloak' in images:
            print(f'  keycloak: {images['keycloak']}')
        else:
            print(f'  keycloak: {COLOR_GREY}not created{COLOR_RESET}')
        if 'services' in images:
            print(f'  services: {images['services']}')
        else:
            print(f'  services: {COLOR_GREY}not created{COLOR_RESET}')
        if 'sentinel' in images:
            print(f'  sentinel: {images['sentinel']}')
        else:
            print(f'  sentinel: {COLOR_GREY}not created{COLOR_RESET}')
        print()


        print('stacks:')
        if 'vpc' in self.cache:
            print(f'       vpc stack: {COLOR_GREEN}created{COLOR_RESET}')
        else:
            print(f'       vpc stack: {COLOR_GREY}not created{COLOR_RESET}')

        if 'rds' in self.cache:
            print(f'       rds stack: {COLOR_GREEN}created{COLOR_RESET}')
        else:
            print(f'       rds stack: {COLOR_GREY}not created{COLOR_RESET}')

        if 'services' in self.cache:
            print(f'  services stack: {COLOR_GREEN}created{COLOR_RESET}')
        else:
            print(f'  services stack: {COLOR_GREY}not created{COLOR_RESET}')
        print()

        if 'rds' in self.cache:
            rds = self.cache['rds']
            print(f'RDS instance:\n  {rds['host']}:{rds['port']}')
            print()

        if 'services' in self.cache:
            resp = self.aws.ec2.describe_instances(
                Filters=[
                    {
                        'Name': 'tag:veraison-deployment',
                        'Values': [
                            args.deployment_name,
                        ],
                    },
                ],
                MaxResults=64,
            )

            instances = defaultdict(list)
            for reservation in resp['Reservations']:
                for instance in reservation['Instances']:
                    for tag in instance['Tags']:
                        if (tag['Key'] == 'deployment-instance-name' and
                                instance['PrivateDnsName']):
                            instances[tag['Value']].append(instance['PrivateDnsName'])
                            break

            if instances:
                print('EC2 instances:')
                for instance_type, hosts in instances.items():
                    for host in hosts:
                        print(f'  {host}\t({instance_type})')


# }}} commands


class Port(int):
    def __init__(self, val):
        val = int(val)
        if val < 1 or val > 65535:
            raise ValueError(f'must in range [1-65535]')
        self = val


class Percent(int):
    def __init__(self, val):
        val = int(val)
        if val < 0 or val > 100:
            raise ValueError(f'must in range [0-100]')
        self = val


class StoreIntList(argparse.Action):

    def __call__(self, parser, namespace, values, option_string=None):
        setattr(namespace, self.dest, [int(v) for v in values.split(',')])  # pyright: ignore


class LogFormatter(logging.Formatter):

    fmt = f'{{}}%(asctime)s %(name)s %(levelname)s{COLOR_RESET}: %(message)s'

    level_formats = {
        logging.DEBUG: fmt.format(COLOR_DARK_GREY),
        logging.INFO: fmt.format(COLOR_MEDIUM_GREY),
        logging.WARNING: fmt.format(COLOR_YELLOW),
        logging.ERROR: fmt.format(COLOR_RED),
        logging.CRITICAL: fmt.format(COLOR_BOLD_RED),
    }

    def format(self, record):
        log_fmt = self.level_formats.get(record.levelno)
        formatter = logging.Formatter(log_fmt)
        return formatter.format(record)


if __name__ == '__main__':
    handler = logging.StreamHandler()
    handler.setLevel(logging.DEBUG)
    handler.setFormatter(LogFormatter())
    logging.basicConfig(level=logging.INFO, handlers=[handler])
    logging.getLogger('botocore').setLevel(logging.WARNING)
    logging.getLogger("paramiko").setLevel(logging.WARNING)

    aws = Aws(
        aws_access_key_id=os.getenv('AWS_ACCESS_KEY'),
        aws_secret_access_key=os.getenv('AWS_SECRET_KEY'),
        aws_session_token=os.getenv('AWS_SESSION_TOKEN'),
        profile_name=os.getenv('AWS_PROFILE'),
    )

    cmd_map = {}
    for name, cmd_cls in inspect.getmembers(
            sys.modules[__name__],
            lambda x: inspect.isclass(x) and issubclass(x, BaseCommand) and x is not BaseCommand):
        if not name[0].isupper():
            continue  # ignore variable bindings
        assert cmd_cls.name, f'{cmd_cls} does not define a name'
        cmd = cmd_cls(aws)
        assert cmd.name not in cmd_map, f'duplicate name {cmd.name}'
        cmd_map[cmd.name] = cmd
        for alias in cmd.aliases:
            assert alias not in cmd_map, f'duplicate alias {alias}'
            cmd_map[alias] = cmd

    parser = argparse.ArgumentParser()
    parser.add_argument('-d', '--deployment-name',
                        help='the name for this deployment; this is used in a number '
                             'places, including AWS resources tags')
    parser.add_argument('-f', '--force', action='store_true',
                        help='force overwrite of exiting resources')
    parser.add_argument('-W', '--wait-period', type=int, default=1,
                        help='period (in seconds) to wait between polls to AWS for '
                             'long-running command progress')
    parser.add_argument('-v', '--verbose', action='store_true',
                        help='show DEBUG level messages')
    parser.add_argument('-q', '--quiet', action='store_true',
                        help='hide INFO level messages')
    parser.add_argument(
        '--cache-dir', default=xdg.BaseDirectory.save_data_path('veraison/aws'),
        help='location that will be used for local deployment data',
    )
    parser.add_argument(
        '--no-error', action='store_false', dest='fail_with_error',
        help='do not report command failures as errors',
    )

    subparsers = parser.add_subparsers(dest='command', required=True)
    for name, command in cmd_map.items():
        if name == command.name:
            command.register(subparsers)

    args = parser.parse_args()

    os.makedirs(args.cache_dir, exist_ok=True)
    current_deployment_path = os.path.join(args.cache_dir, 'current_deployment')
    if args.deployment_name:
        with open(current_deployment_path, 'w') as wfh:
            wfh.write(args.deployment_name)
    else:
        if os.path.isfile(current_deployment_path):
            with open(current_deployment_path) as fh:
                args.deployment_name = fh.read().strip()
        else:
            logging.critical('no current deployment exists; '
                             'please use -d/--deployment-name to specify')
            sys.exit(1)

    cmd = cmd_map[args.command]
    cmd.fail_with_error = args.fail_with_error
    try:
        cmd.execute(args)
    except Exception as e:
        write = cmd.logger.critical if args.fail_with_error else cmd.logger.info
        write(f'{e.__class__.__name__}: {e}')
